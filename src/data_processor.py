import pandas as pd
import os
from typing import List, Dict
from config.config_manager import ConfigManager

class DataProcessor:
    def __init__(self, config: ConfigManager):
        self.config = config
        self.data_config = config.get_data_config()
        self.setup_conversion_maps()
    
    def setup_conversion_maps(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„ØªØ­ÙˆÙŠÙ„"""
        # Ø¹Ø±Ø¨ÙŠØ²ÙŠ Ø¨Ø£Ø±Ù‚Ø§Ù…
        self.arabizi_numbers = {
            "Ø£": "'", "Ø§": "a", "Ø¥": "i", "Ø¢": "a'", "Ø¡": "'",
            "Ø¨": "b", "Øª": "t", "Ø«": "th", "Ø¬": "g", "Ø­": "7", "Ø®": "7'",
            "Ø¯": "d", "Ø°": "th", "Ø±": "r", "Ø²": "z", "Ø³": "s", "Ø´": "sh",
            "Øµ": "9", "Ø¶": "9'", "Ø·": "6", "Ø¸": "6'", "Ø¹": "3", "Øº": "3'",
            "Ù": "f", "Ù‚": "8", "Ùƒ": "k", "Ù„": "l", "Ù…": "m", "Ù†": "n",
            "Ù‡": "h", "Ø©": "h'", "Ùˆ": "w", "ÙŠ": "y", "Ù‰": "a",
        }
        
        # ØªØ­ÙˆÙŠÙ„ ØµÙˆØªÙŠ
        self.transliteration_map = {
            "Ø£": "a", "Ø§": "a", "Ø¥": "i", "Ø¨": "b", "Øª": "t", "Ø«": "th",
            "Ø¬": "j", "Ø­": "h", "Ø®": "kh", "Ø¯": "d", "Ø°": "dh", "Ø±": "r",
            "Ø²": "z", "Ø³": "s", "Ø´": "sh", "Øµ": "s", "Ø¶": "d", "Ø·": "t",
            "Ø¸": "z", "Ø¹": "'", "Øº": "gh", "Ù": "f", "Ù‚": "q", "Ùƒ": "k",
            "Ù„": "l", "Ù…": "m", "Ù†": "n", "Ù‡": "h", "Ø©": "t", "Ùˆ": "w",
            "ÙŠ": "y", "Ù‰": "a",
        }
    
    def load_dataset(self, dataset_type: str = "both") -> pd.DataFrame:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©"""
        data_files = self.data_config['input_files']
        
        if dataset_type == "harmful":
            file_path = data_files['harmful']
            df = pd.read_csv(file_path)
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df)} Ø³Ø¬Ù„ Ù…Ù† {file_path}")
            
        elif dataset_type == "regional":
            file_path = data_files['regional']
            df = pd.read_csv(file_path)
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df)} Ø³Ø¬Ù„ Ù…Ù† {file_path}")
            
        else:  # both
            df1 = pd.read_csv(data_files['harmful'])
            df2 = pd.read_csv(data_files['regional'])
            df = pd.concat([df1, df2], ignore_index=True)
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df)} Ø³Ø¬Ù„ Ù…Ù† ÙƒÙ„Ø§ Ø§Ù„Ù…Ù„ÙÙŠÙ†")
        
        # Ø£Ø®Ø° Ø¹ÙŠÙ†Ø© Ø¥Ø°Ø§ Ù…Ø·Ù„ÙˆØ¨
        sample_size = self.data_config.get('sample_size', -1)
        if sample_size > 0 and sample_size < len(df):
            df = df.sample(sample_size, random_state=42)
            print(f"ğŸ”¬ ØªÙ… Ø£Ø®Ø° Ø¹ÙŠÙ†Ø© Ø­Ø¬Ù…Ù‡Ø§ {len(df)}")
        
        return df
    
    def convert_to_arabizi(self, text: str) -> str:
        """ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø¹Ø±Ø¨ÙŠØ²ÙŠ Ø¨Ø£Ø±Ù‚Ø§Ù…"""
        result = ""
        for char in str(text):
            result += self.arabizi_numbers.get(char, char)
        return result
    
    def convert_to_transliteration(self, text: str) -> str:
        """ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ transliteration"""
        result = ""
        for char in str(text):
            result += self.transliteration_map.get(char, char)
        return result
    
    def add_diacritics(self, text: str) -> str:
        """Ø¥Ø¶Ø§ÙØ© ØªØ´ÙƒÙŠÙ„ Ù…Ø¨Ø³Ø·"""
        # Ù‡Ø°Ù‡ Ù†Ø³Ø®Ø© Ù…Ø¨Ø³Ø·Ø© - ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡Ø§ Ø¨Ù…ÙƒØªØ¨Ø© Ù…ØªØ®ØµØµØ©
        return str(text)  # ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø£Ø¶Ù Ø§Ù„ØªØ´ÙƒÙŠÙ„ Ù‡Ù†Ø§
    
    def process_data(self, dataset_type: str = "both") -> pd.DataFrame:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
        df = self.load_dataset(dataset_type)
        
        print("ğŸ”„ Ø¨Ø¯Ø¡ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ...")
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª
        df['arabizi'] = df['Arabic'].apply(self.convert_to_arabizi)
        df['transliteration'] = df['Arabic'].apply(self.convert_to_transliteration)
        df['diacritized'] = df['Arabic'].apply(self.add_diacritics)
        
        print("âœ… Ø§ÙƒØªÙ…Ù„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ")
        
        # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­ÙˆÙ„Ø©
        output_dir = self.data_config['output_dir']
        os.makedirs(output_dir, exist_ok=True)
        
        output_path = os.path.join(output_dir, f'processed_{dataset_type}.csv')
        df.to_csv(output_path, index=False, encoding='utf-8')
        print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ: {output_path}")
        
        return df