"""
RobostAI - Arabic LLM Security Evaluation Framework

This package provides tools and methodologies for evaluating the safety and robustness
of Arabic Large Language Models (LLMs) against various jailbreaking techniques,
including transliteration and Arabizi.
"""

__author__ = "Mohamed Gomaa"
__version__ = "0.1.0"
__license__ = "MIT"
__description__ = "Arabic LLM Red Teaming and Safety Evaluation Framework"
